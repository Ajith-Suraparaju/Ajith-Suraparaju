# Hello, I'm Ajith Suraparaju <br/><a href="https://github.com/ajith-suraparaju">Data Engineer</a></h1> 
[I invite you to review my resume](https://github.com/Ajith-Suraparaju/Ajith-Suraparaju/blob/main/Ajith_Suraparaju-Data_Engineer.pdf) </a>

Experienced Data Engineer with 3+ years in building and optimizing data pipelines using Python, SQL, and big data tools like Apache Spark and Kafka. Improved data processing speeds by 40% through efficient ETL processes. Skilled in cloud platforms such as AWS and Azure and proficient in data warehousing with Redshift and Snowflake. Seeking to apply expertise in a Data Engineering role. </a>

## Certifications

- [**AWS Certified: Data Engineer Associate**](https://github.com/Ajith-Suraparaju/Ajith-Suraparaju/blob/main/AWS%20Certified%20Data%20Engineer%20-%20Associate%20certificate.pdf)
  - Issued: September 2024

- [**Microsoft Certified: Azure Data Fundamentals**](https://github.com/Ajith-Suraparaju/Ajith-Suraparaju/blob/main/Credentials%20-%20suraparajuajith%20%20Microsoft%20Learn.pdf)
  - Issued: May 2024

## Contact me
<a href="mailto:ajith1997raju@gmail.com"><img src="https://img.shields.io/badge/-Email-D14836?&style=for-the-badge&logo=gmail&logoColor=white" /></a>
<a href="tel:2163345668"><img src="https://img.shields.io/badge/-Telephone-25D366?style=for-the-badge&logo=whatsapp&logoColor=white" /></a>
<a href="https://www.linkedin.com/in/ajith-suraparaju/"><img src="https://img.shields.io/badge/-LinkedIn-0072b1?&style=for-the-badge&logo=linkedin&logoColor=white" /></a> </h1>



## Languages and Tools</a>
<p align="left"> 
  <a href="https://azure.microsoft.com/en-in/" target="_blank" rel="noreferrer"> <img src="https://www.vectorlogo.zone/logos/microsoft_azure/microsoft_azure-icon.svg" alt="azure" width="40" height="40"/> 
  </a> 
  <a href="https://www.python.org" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/python/python-original.svg" alt="python" width="40" height="40"/> 
  </a> 
  <a href="https://www.mysql.com/" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/mysql/mysql-original-wordmark.svg" alt="mysql" width="40" height="40"/> </a> 
  <a href="https://spark.apache.org/" target="_blank" rel="noreferrer"> 
    <img src="https://www.vectorlogo.zone/logos/apache_spark/apache_spark-icon.svg" alt="apache-spark" width="40" height="40"/> </a> 
  <a href="https://hadoop.apache.org/" target="_blank" rel="noreferrer"> <img src="https://www.vectorlogo.zone/logos/apache_hadoop/apache_hadoop-icon.svg" alt="hadoop" width="40" height="40"/> 
  </a> <a href="https://hive.apache.org/" target="_blank" rel="noreferrer"> <img src="https://www.vectorlogo.zone/logos/apache_hive/apache_hive-icon.svg" alt="hive" width="40" height="40"/> </a> 
  <a href="https://databricks.com/" target="_blank" rel="noreferrer"> 
    <img src="https://www.vectorlogo.zone/logos/databricks/databricks-icon.svg" alt="databricks" width="40" height="40"/> </a> 
  <a href="https://www.snowflake.com/" target="_blank" rel="noreferrer"> 
    <img src="https://www.vectorlogo.zone/logos/snowflake/snowflake-icon.svg" alt="snowflake" width="40" height="40"/> </a> 
  <a href="https://powerbi.microsoft.com/" target="_blank" rel="noreferrer"> 
    <img src="https://www.vectorlogo.zone/logos/microsoft_powerbi/microsoft_powerbi-icon.svg" alt="powerbi" width="40" height="40"/> </a>
  <a href="https://git-scm.com/" target="_blank" rel="noreferrer"> <img src="https://www.vectorlogo.zone/logos/git-scm/git-scm-icon.svg" alt="git" width="40" height="40"/> </a> 
  <a href="https://www.microsoft.com/en-us/sql-server" target="_blank" rel="noreferrer"> <img src="https://www.svgrepo.com/show/303229/microsoft-sql-server-logo.svg" alt="mssql" width="40" height="40"/> </a> 
  <a href="https://www.mongodb.com/" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/mongodb/mongodb-original-wordmark.svg" alt="mongodb" width="40" height="40"/> </a> 
  <a href="https://pandas.pydata.org/" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/2ae2a900d2f041da66e950e4d48052658d850630/icons/pandas/pandas-original.svg" alt="pandas" width="40" height="40"/> </a> 
  <a href="https://pytorch.org/" target="_blank" rel="noreferrer"> <img src="https://www.vectorlogo.zone/logos/pytorch/pytorch-icon.svg" alt="pytorch" width="40" height="40"/> </a>  
</p>

## Experience </a>

**Big Data Engineer | Pacs                                               Remote, USA | January 2024 - Present**</a>

Technologies: SQL, Python, Hive, Hadoop, MongoDB, AWS Lake Formation, AWS QuickSight</a>

•	Built and optimized big data solutions with Hadoop and Hive, enabling the organization to process and analyze over 1 billion records daily, improving operational efficiency by 25%.</a>

•	Enhanced data governance using AWS Lake Formation, ensuring data privacy and compliance by implementing automated role-based access controls.</a>

•	Integrated and managed NoSQL databases like MongoDB for high-performance data storage, reducing query response times by 30% for high-volume transactions.</a>

•	Created real-time analytics dashboards with AWS QuickSight, delivering key performance indicators to leadership and reducing decision-making time by 20%.</a>

•	Automated data quality checks in ETL processes, increasing data accuracy and reducing manual error correction efforts by 40%.</a>

**Data Engineer | Kohler Co.                                         Indiana, USA| May 2023 – December 2023** </a>

Technologies: Python, SQL, Apache Spark, AWS Glue, AWS EMR, Redshift, S3, Power BI, Kafka, Databricks</a>

•	Designed and maintained scalable ETL pipelines using Apache Spark and AWS Glue, reducing data processing times by 40% and increasing data accessibility across departments by 30%.</a>

•	Engineered data ingestion processes with AWS EMR and Databricks, enabling real-time processing of large datasets and improving data analysis speeds by 50%.</a> 

•	Optimized data warehousing using AWS Redshift and S3 to handle high-volume transactions, achieving a 35% reduction in storage costs while enhancing data retrieval efficiency.</a>

•	Implemented data streaming solutions with Apache Kafka, supporting fault-tolerant, real-time data pipelines with 99.9% uptime, scaling operations for business demands.</a>

•	Developed interactive dashboards in Power BI to visualize key metrics, providing stakeholders with actionable insights and reducing manual reporting time by 60%.</a>

**Jr Data Engineer | MoneyTap                                          Pune, India | June 2020 – July 2022**</a>

Technologies: PySpark, SQL, AWS Redshift, PostgreSQL, Amazon Athena, Kafka, Azure Services </a>

•	Developed real-time data pipelines with PySpark and Amazon Athena, facilitating fraud detection and transaction monitoring with 30% faster alert generation.</a>

•	Implemented secure data warehousing solutions on AWS Redshift and PostgreSQL, achieving a 25% increase in storage efficiency and data security compliance.</a>

•	Deployed and managed event-driven data streams using Apache Kafka on Azure, enabling distributed processing with a 99% reliability rate and reducing data lag.</a>

•	Utilized SQL for complex data transformations, optimizing query performance and enhancing data accessibility for business intelligence applications.</a>

•	Collaborated with cross-functional teams to deliver integrated solutions, aligning data engineering projects with business needs and boosting adoption rates by 15%.</a>


**Brief Overview**

The project overview utilized a step-by-step approach leveraging Azure technologies to optimize data workflows. Beginning with Azure Data Factory, orchestrated seamless data pipelines for ingestion data from On-Premises and transformation. Utilizing Azure Databricks, enhanced data processing capabilities with Apache Spark for scalable analytics. Integration with Azure Synapse Analytics facilitated streamlined data warehousing and querying. Azure SQL Database ensured robust data management and querying capabilities. Azure Data Lake Storage supports efficient storage and management of large-scale data. Through Azure DevOps, agile project management and continuous integration for efficient deployment are maintained. This comprehensive Azure ecosystem enabled us to deliver scalable, secure, and performance-driven data solutions tailored to business needs.



## CO-Curricular & Extracurricular Activities
- Volunteer for Sigmoid 2018 and 2019, a Computer Science and Engineering branch technical event.
- Captain of the National Athletic team for the National Athletic Meet.
- Won the Gold medal in the Triple Jump at the National Athletic Meet.



