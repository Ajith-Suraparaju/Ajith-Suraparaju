# Hello, I'm Ajith Suraparaju <br/><a href="https://github.com/ajith-suraparaju">Data Engineer</a></h1> 
[I invite you to review my resume](https://github.com/Ajith-Suraparaju/Ajith-Suraparaju/blob/main/Ajith_Suraparaju-Data_Engineer.pdf) </a>

Experienced and certified Data Engineer with a strong foundation in designing, implementing, and optimizing batch and streaming data pipelines. Proficient in various technologies, including Python, SQL, Apache Spark, Databricks, and Microsoft Azure. Skilled in ensuring operational stability, data quality, and compliance throughout the data pipeline process. Adept at collaborating with cross-functional teams to deliver data-driven solutions that enhance decision-making processes and drive business growth. </a>

## Certifications

- [**Microsoft Certified: Azure Data Engineer Associate**](https://github.com/Ajith-Suraparaju/Ajith-Suraparaju/blob/main/Credentials%20-%20suraparajuajith%20%20Microsoft%20Learn.pdf)
  - Issued: June 2024

- [**Microsoft Certified: Azure Data Fundamentals**](https://github.com/Ajith-Suraparaju/Ajith-Suraparaju/blob/main/Credentials%20-%20suraparajuajith%20%20Microsoft%20Learn.pdf)
  - Issued: May 2024

## Contact me
<a href="mailto:ajith1997raju@gmail.com"><img src="https://img.shields.io/badge/-Email-D14836?&style=for-the-badge&logo=gmail&logoColor=white" /></a>
<a href="tel:2163345668"><img src="https://img.shields.io/badge/-Telephone-25D366?style=for-the-badge&logo=whatsapp&logoColor=white" /></a>
<a href="https://www.linkedin.com/in/ajith-suraparaju/"><img src="https://img.shields.io/badge/-LinkedIn-0072b1?&style=for-the-badge&logo=linkedin&logoColor=white" /></a> </h1>



## Languages and Tools</a>
<p align="left"> 
  <a href="https://azure.microsoft.com/en-in/" target="_blank" rel="noreferrer"> <img src="https://www.vectorlogo.zone/logos/microsoft_azure/microsoft_azure-icon.svg" alt="azure" width="40" height="40"/> 
  </a> 
  <a href="https://www.python.org" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/python/python-original.svg" alt="python" width="40" height="40"/> 
  </a> 
  <a href="https://www.mysql.com/" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/mysql/mysql-original-wordmark.svg" alt="mysql" width="40" height="40"/> </a> 
  <a href="https://spark.apache.org/" target="_blank" rel="noreferrer"> 
    <img src="https://www.vectorlogo.zone/logos/apache_spark/apache_spark-icon.svg" alt="apache-spark" width="40" height="40"/> </a> 
  <a href="https://hadoop.apache.org/" target="_blank" rel="noreferrer"> <img src="https://www.vectorlogo.zone/logos/apache_hadoop/apache_hadoop-icon.svg" alt="hadoop" width="40" height="40"/> 
  </a> <a href="https://hive.apache.org/" target="_blank" rel="noreferrer"> <img src="https://www.vectorlogo.zone/logos/apache_hive/apache_hive-icon.svg" alt="hive" width="40" height="40"/> </a> 
  <a href="https://databricks.com/" target="_blank" rel="noreferrer"> 
    <img src="https://www.vectorlogo.zone/logos/databricks/databricks-icon.svg" alt="databricks" width="40" height="40"/> </a> 
  <a href="https://www.snowflake.com/" target="_blank" rel="noreferrer"> 
    <img src="https://www.vectorlogo.zone/logos/snowflake/snowflake-icon.svg" alt="snowflake" width="40" height="40"/> </a> 
  <a href="https://powerbi.microsoft.com/" target="_blank" rel="noreferrer"> 
    <img src="https://www.vectorlogo.zone/logos/microsoft_powerbi/microsoft_powerbi-icon.svg" alt="powerbi" width="40" height="40"/> </a>
  <a href="https://git-scm.com/" target="_blank" rel="noreferrer"> <img src="https://www.vectorlogo.zone/logos/git-scm/git-scm-icon.svg" alt="git" width="40" height="40"/> </a> 
  <a href="https://www.microsoft.com/en-us/sql-server" target="_blank" rel="noreferrer"> <img src="https://www.svgrepo.com/show/303229/microsoft-sql-server-logo.svg" alt="mssql" width="40" height="40"/> </a> 
  <a href="https://www.mongodb.com/" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/mongodb/mongodb-original-wordmark.svg" alt="mongodb" width="40" height="40"/> </a> 
  <a href="https://pandas.pydata.org/" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/2ae2a900d2f041da66e950e4d48052658d850630/icons/pandas/pandas-original.svg" alt="pandas" width="40" height="40"/> </a> 
  <a href="https://pytorch.org/" target="_blank" rel="noreferrer"> <img src="https://www.vectorlogo.zone/logos/pytorch/pytorch-icon.svg" alt="pytorch" width="40" height="40"/> </a>  
</p>

## Experience </a>

**Project 2: Data Pipeline Optimization Specialist**
- Designed and implemented data pipelines using Azure Data Factory and Databricks, cutting processing time by 35%, and utilized Python and Azure Cloud services for efficient data processing and transformation.
- Collaborated with developers, tech leads, and stakeholders to gather data requirements, resulting in the design and deployment of data solutions aligned with business needs. This collaborative effort boosted project delivery efficiency. Proficient in software development methodologies, including waterfall and agile, ensuring flexibility and adaptability in data solution development.
- Implemented data security measures, reducing security incidents by 20%, and used Cloud Composer/Airflow and Dataflow/Data Fusion for process automation and data validation, enhancing data governance.
- Analyzed complex data structures and designed large-scale pipelines. It improved ETL efficiency by 40% using Teradata utilities. Engaged in agile activities and user story grooming to refine data workflows.
- Created data visualizations and reports with MicroStrategy and Tableau, aiding decision-making and strategic planning. Addressed industry-specific challenges in the Health Care/PBM domain, improving data accuracy and reporting speed by 25%.

**Project 1: ETL Process Engineer**

- In the Banking Domain, tasked with developing and automating a comprehensive monthly reporting system for credit card offers and usage.
- This initiative aimed to meet client demands for detailed insights into issued credit cards, offers distributed, and user utilization patterns.
- Leveraging Azure Data Factory, I orchestrated data extraction and transfer from DB2 databases to Azure Data Lake Storage, ensuring seamless integration of customer, credit card, offer, and product information.
- As the project evolved, I transitioned to Databricks and Apache Spark for advanced data transformations, employing Spark SQL and data frames to enhance efficiency and scalability.
- Collaborating closely with visualization experts using MicroStrategy ensured that insights were communicated effectively.
- Daily responsibilities included optimizing data pipelines, monitoring performance, and implementing automation using tools like Autosys while maintaining rigorous documentation to support data governance and strategic decision-making.
- This role underscored my proficiency in leveraging cutting-edge technologies to deliver robust data solutions in a dynamic banking environment.

**Brief Overview**

The project overview utilized a step-by-step approach leveraging Azure technologies to optimize data workflows. Beginning with Azure Data Factory, orchestrated seamless data pipelines for ingestion data from On-Premises and transformation. Utilizing Azure Databricks, enhanced data processing capabilities with Apache Spark for scalable analytics. Integration with Azure Synapse Analytics facilitated streamlined data warehousing and querying. Azure SQL Database ensured robust data management and querying capabilities. Azure Data Lake Storage supports efficient storage and management of large-scale data. Through Azure DevOps, agile project management and continuous integration for efficient deployment are maintained. This comprehensive Azure ecosystem enabled us to deliver scalable, secure, and performance-driven data solutions tailored to business needs.


**Solution Architecture**

![GIF](https://media.licdn.com/dms/image/D4E22AQE7dZmkAFFJ3g/feedshare-shrink_1280/0/1698074850766?e=1721865600&v=beta&t=nRRsu2UfWlT7XsEdLzeivoHlosWjpfnWudZLiiNwGgk)

## CO-Curricular & Extracurricular Activities
- Volunteer for Sigmoid 2018 and 2019, a Computer Science and Engineering branch technical event.
- Captain of the National Athletic team for the National Athletic Meet.
- Won the Gold medal in the Triple Jump at the National Athletic Meet.



